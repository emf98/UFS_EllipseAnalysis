{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191cb9b8",
   "metadata": {},
   "source": [
    "### Random Forests at 14-days leadtime for all regions.\n",
    "\n",
    "File generated 9/18/2025 for Chapter 4 of Dissertation. \n",
    "Modified 12/2/2025 for use in UFS analysis. \n",
    "\n",
    "This file utilizes definition statements containing RF architecture to create three separate RF models, each for a designated forecast region. \n",
    "\n",
    "Forecast leadtime can be changed as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85424968",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 13:51:45.716282: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-05 13:51:45.772815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-05 13:51:45.772853: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-05 13:51:45.773904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-05 13:51:45.785782: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-05 13:51:47.324955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "##just to stop the excess number of warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#relevant import statements\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import sample\n",
    "\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import keras\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698f62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import definitions \n",
    "from SkillStats_MOD import BSS, RAS, PAS\n",
    "\n",
    "from RF_archMOD import rf_featselect,rf_90thpercentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb544f9-6ae8-44cc-885d-3197a9731459",
   "metadata": {},
   "source": [
    "I am going to do a modified version of the architecture def here because I have to change the dataset structure. \n",
    "\n",
    "Start with bringing in the old data for training/validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62081138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 149, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load OG input data, it is max/min standardized, NaNs removed\n",
    "#stratospheric polar vortex ellipse diagnostics from Fernandez et al 2025 (in review)\n",
    "infile = open(\"./old_data/nolag_extendedanom_input.p\", 'rb') \n",
    "nolag_input = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "nolag_input.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf69a",
   "metadata": {},
   "source": [
    "The input data stays the same regardless of forecast region. \n",
    "\n",
    "The original array starts on October 19th. The shift send this forward to November 2nd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d20b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 135 #129 for 20, 119 for 30.\n",
    "inp1 = np.empty((52,idx,7)) #cnew input array, 14 day lag. \n",
    "shift = 14\n",
    "\n",
    "##reshaping to change lag in metrics for input\n",
    "inp1[:,:,0] = nolag_input[:52,shift:,0] ##wind\n",
    "inp1[:,:,1] = nolag_input[:52,shift:,1] ##ratio\n",
    "inp1[:,:,2] = nolag_input[:52,shift:,2] ##latitude\n",
    "inp1[:,:,3] = nolag_input[:52,shift:,3] ##longitude\n",
    "inp1[:,:,4] = nolag_input[:52,shift:,4] ##size\n",
    "inp1[:,:,5] = nolag_input[:52,shift:,5] ##ephi\n",
    "inp1[:,:,6] = nolag_input[:52,shift:,6] ##gph\n",
    "\n",
    "inp = inp1.reshape(52*idx,7)\n",
    "\n",
    "#convert to pandas dataframe\n",
    "input1 = pd.DataFrame(inp)\n",
    "#label columns of variables for input data\n",
    "col_names = ['wind','rat','cenlat','cenlon','size','ephi','gph']\n",
    "input1.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce14c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load in desired TESTING dataset... varies based on prototype.\n",
    "infile = open(\"./new_data/input_ERA5.p\", 'rb') \n",
    "testing_input = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "inp = testing_input.reshape(56*18,7)\n",
    "\n",
    "#convert to pandas dataframe\n",
    "input2 = pd.DataFrame(inp)\n",
    "#label columns of variables for input data\n",
    "col_names = ['wind','rat','cenlat','cenlon','size','ephi','gph']\n",
    "input2.columns = col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40125d95",
   "metadata": {},
   "source": [
    "### Begin RF Feature selection test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e0b99c-85bc-400e-8c4e-994cfb0063cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def feat_imp_plot(important,input1,files):\n",
    "    imp = np.nanmean(important, axis = 0)\n",
    "    imp.shape\n",
    "    \n",
    "    #plot features by relative importance\n",
    "    indices = np.argsort(imp)[::-1]  #sort by importance\n",
    "    c = [\"navy\",\"royalblue\",\"slateblue\",\"blueviolet\",\"darkviolet\",\"purple\",\"mediumvioletred\",\"magenta\"]\n",
    "    \n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.title(f'Average Feature Importances Across 100 CVs, {str(files)}',fontsize =18)\n",
    "    plt.barh(range(input1.shape[1]), imp[indices], align=\"center\", color = c)\n",
    "    plt.yticks(range(input1.shape[1]), input1.columns[indices],fontsize =14)\n",
    "    plt.xticks(fontsize =14)\n",
    "    plt.xlabel(\"Relative Importance\",fontsize =16)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(f'./images/FeatureImportance_{str(files)}.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9a03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of cross validations\n",
    "n = 100\n",
    "\n",
    "regions = ['eur','nova','seus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9a202",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Europe_ERA5 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 57.89%\n",
      "Accuracy, Training: 63.17%\n",
      "Accuracy, Testing: 60.62%\n",
      "_____________________________________\n",
      "Working on Europe_Prototype5 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 57.65%\n",
      "Accuracy, Training: 63.17%\n",
      "Accuracy, Testing: 61.66%\n",
      "_____________________________________\n",
      "Working on Europe_Prototype6 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 56.99%\n",
      "Accuracy, Training: 63.12%\n",
      "Accuracy, Testing: 56.60%\n",
      "_____________________________________\n",
      "Working on Europe_Prototype7 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 57.53%\n",
      "Accuracy, Training: 63.13%\n",
      "Accuracy, Testing: 58.26%\n",
      "_____________________________________\n",
      "Working on Europe_Prototype8 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 57.65%\n",
      "Accuracy, Training: 63.13%\n",
      "Accuracy, Testing: 53.77%\n",
      "_____________________________________\n",
      "Working on Canada_ERA5 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 69.77%\n",
      "Accuracy, Training: 72.23%\n",
      "Accuracy, Testing: 74.56%\n",
      "_____________________________________\n",
      "Working on Canada_Prototype5 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 70.01%\n",
      "Accuracy, Training: 72.13%\n",
      "Accuracy, Testing: 68.25%\n",
      "_____________________________________\n",
      "Working on Canada_Prototype6 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 70.29%\n",
      "Accuracy, Training: 72.17%\n",
      "Accuracy, Testing: 67.61%\n",
      "_____________________________________\n",
      "Working on Canada_Prototype7 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 70.04%\n",
      "Accuracy, Training: 72.18%\n",
      "Accuracy, Testing: 68.93%\n",
      "_____________________________________\n",
      "Working on Canada_Prototype8 ...\n",
      "Begin CV ...\n",
      "###################################################\n",
      "Accuracy, Validation: 70.06%\n",
      "Accuracy, Training: 72.16%\n",
      "Accuracy, Testing: 69.14%\n",
      "_____________________________________\n",
      "Working on SEUS_ERA5 ...\n",
      "Begin CV ...\n"
     ]
    }
   ],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "for i in range(len(regions)):\n",
    "    ##EUROPE\n",
    "    if regions[i] == 'eur':\n",
    "        files = ['Europe_ERA5','Europe_Prototype5','Europe_Prototype6','Europe_Prototype7','Europe_Prototype8']\n",
    "        for j in range(len(files)):\n",
    "            print(f'Working on {str(files[j])} ...')\n",
    "            eur_important = rf_featselect(n,shift,idx,input1,input2,regions[i],files[j])\n",
    "            feat_imp_plot(eur_important,input1,files[j])\n",
    "            print('_____________________________________')\n",
    "    ##CANADA\n",
    "    if regions[i] == 'nova':\n",
    "        files = ['Canada_ERA5','Canada_Prototype5','Canada_Prototype6','Canada_Prototype7','Canada_Prototype8']\n",
    "        for j in range(len(files)):\n",
    "            print(f'Working on {str(files[j])} ...')\n",
    "            can_important = rf_featselect(n,shift,idx,input1,input2,regions[i],files[j])\n",
    "            feat_imp_plot(can_important,input1,files[j])\n",
    "            print('_____________________________________')\n",
    "    ##SEUS\n",
    "    if regions[i] == 'seus':\n",
    "        files = ['SEUS_ERA5','SEUS_Prototype5','SEUS_Prototype6','SEUS_Prototype7','SEUS_Prototype8']\n",
    "        for j in range(len(files)):\n",
    "            print(f'Working on {str(files[j])} ...')\n",
    "            seus_important = rf_featselect(n,shift,idx,input1,input2,regions[i],files[j])\n",
    "            feat_imp_plot(seus_important,input1,files[j])\n",
    "            print('_____________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab1417",
   "metadata": {},
   "source": [
    "## Second RF run post feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef75b9f-00a3-4029-b6d4-96f1827d530e",
   "metadata": {},
   "source": [
    "### Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9782b-65ea-4b65-bde1-51805dad8dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "files = ['Europe_ERA5','Europe_Prototype5','Europe_Prototype6','Europe_Prototype7','Europe_Prototype8']\n",
    "eur_input1 = input1[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "eur_input2 = input2[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "\n",
    "for j in range(len(files)):\n",
    "    print(f'Working on {str(files[j])} ...')\n",
    "    \n",
    "    ##CONSTANT ERA5 OUTPUT\n",
    "    infile = open(f'./new_data/2classtemps_Europe_ERA5.p',\"rb\",)\n",
    "    ERA5_temp = pickle.load(infile) \n",
    "    infile.close()\n",
    "\n",
    "    eur_test90, eur_fulltest, eur_shap_obj, eur_posXtest, eur_FposXtest, eur_negXtest, eur_FnegXtest, acc_reg2_test, acc_reg3_test, acc_reg4_test = rf_90thpercentile(n,shift, idx, eur_input1, eur_input2, ERA5_temp, 'eur', files[j])\n",
    "    #____________________________________________________#\n",
    "    #plot SHAP\n",
    "    plt.title(f'SHAP Values for Negative Europe Temp Anomalies, {str(files[j])}',fontsize =14, y = 1.05)\n",
    "    ax = shap.plots.beeswarm(eur_shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/SHAP_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    #____________________________________________________#\n",
    "    #plot ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(eur_test90, bins=bins)\n",
    "    countsfull, edgesfull = np.histogram(eur_fulltest, bins=bins)\n",
    "    counts_era5, edges_era5= np.histogram(acc_reg3_test, bins=bins) ##relative to ERA5 truth\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "    \n",
    "    #plot the ERA-5 comparison\n",
    "    plt.bar(edges_era5[:-1], counts_era5, width=np.diff(edges_era5), \n",
    "            edgecolor='black', alpha=0.5, label='Predictions vs. ERA-5 Truth', align='edge', color = 'indigo')\n",
    "    \n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs for 100 CVs, {str(files[j])}',fontsize =12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "    ##export out files to make the next few plots w/o normalization\n",
    "    pickle.dump(eur_posXtest, open(f'./index/pos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FposXtest, open(f'./index/Fpos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_negXtest, open(f'./index/neg_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FnegXtest, open(f'./index/Fneg_{str(files[j])}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9232b-a154-4cda-9a1f-056863c6074d",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd590d-53ee-40c9-a2ea-100952da1964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "files = ['Canada_ERA5','Canada_Prototype5','Canada_Prototype6','Canada_Prototype7','Canada_Prototype8']\n",
    "eur_input1 = input1[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "eur_input2 = input2[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "\n",
    "for j in range(len(files)):\n",
    "    print(f'Working on {str(files[j])} ...')\n",
    "\n",
    "    ##CONSTANT ERA5 OUTPUT\n",
    "    infile = open(f'./new_data/2classtemps_Canada_ERA5.p',\"rb\",)\n",
    "    ERA5_temp = pickle.load(infile) \n",
    "    infile.close()\n",
    "    \n",
    "    eur_test90, eur_fulltest, eur_shap_obj, eur_posXtest, eur_FposXtest, eur_negXtest, eur_FnegXtest, acc_reg2_test, acc_reg3_test, acc_reg4_test = rf_90thpercentile(n,shift, idx, eur_input1, eur_input2, ERA5_temp, 'nova',files[j])\n",
    "    #____________________________________________________#\n",
    "    #plot SHAP\n",
    "    plt.title(f'SHAP Values for Negative Canadian Temp Anomalies, {str(files[j])}',fontsize =14, y = 1.05)\n",
    "    ax = shap.plots.beeswarm(eur_shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/SHAP_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    #____________________________________________________#\n",
    "    #plot ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(eur_test90, bins=bins)\n",
    "    countsfull, edgesfull = np.histogram(eur_fulltest, bins=bins)\n",
    "    counts_era5, edges_era5= np.histogram(acc_reg3_test, bins=bins) ##relative to ERA5 truth\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "    \n",
    "    #plot the ERA-5 comparison\n",
    "    plt.bar(edges_era5[:-1], counts_era5, width=np.diff(edges_era5), \n",
    "            edgecolor='black', alpha=0.5, label='Predictions vs. ERA-5 Truth', align='edge', color = 'indigo')\n",
    "    \n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs for 100 CVs, {str(files[j])}',fontsize =12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "    ##export out files to make the next few plots w/o normalization\n",
    "    pickle.dump(eur_posXtest, open(f'./index/pos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FposXtest, open(f'./index/Fpos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_negXtest, open(f'./index/neg_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FnegXtest, open(f'./index/Fneg_{str(files[j])}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eacbe6d-5fc0-4169-9820-562228794097",
   "metadata": {},
   "source": [
    "### SEUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc079ec-6b5c-4d43-b9f5-4ab2535895db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "files = ['SEUS_ERA5','SEUS_Prototype5','SEUS_Prototype6','SEUS_Prototype7','SEUS_Prototype8']\n",
    "eur_input1 = input1[[\"wind\",\"size\",\"cenlat\",\"gph\"]]\n",
    "eur_input2 = input2[[\"wind\",\"size\",\"cenlat\",\"gph\"]]\n",
    "\n",
    "for j in range(len(files)):\n",
    "    print(f'Working on {str(files[j])} ...')\n",
    "\n",
    "    ##CONSTANT ERA5 OUTPUT\n",
    "    infile = open(f'./new_data/2classtemps_SEUS_ERA5.p',\"rb\",)\n",
    "    ERA5_temp = pickle.load(infile) \n",
    "    infile.close()\n",
    "    \n",
    "    eur_test90, eur_fulltest, eur_shap_obj, eur_posXtest, eur_FposXtest, eur_negXtest, eur_FnegXtest, acc_reg2_test, acc_reg3_test, acc_reg4_test = rf_90thpercentile(n,shift, idx, eur_input1, eur_input2, ERA5_temp, 'seus', files[j])\n",
    "    #____________________________________________________#\n",
    "    #plot SHAP\n",
    "    plt.title(f'SHAP Values for SEUS Temp Anomalies, {str(files[j])}',fontsize =14, y = 1.05)\n",
    "    ax = shap.plots.beeswarm(eur_shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/SHAP_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    #____________________________________________________#\n",
    "    #plot ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(eur_test90, bins=bins)\n",
    "    countsfull, edgesfull = np.histogram(eur_fulltest, bins=bins)\n",
    "    counts_era5, edges_era5= np.histogram(acc_reg3_test, bins=bins) ##relative to ERA5 truth\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "    \n",
    "    #plot the ERA-5 comparison\n",
    "    plt.bar(edges_era5[:-1], counts_era5, width=np.diff(edges_era5), \n",
    "            edgecolor='black', alpha=0.5, label='Predictions vs. ERA-5 Truth', align='edge', color = 'indigo')\n",
    "    \n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs for 100 CVs, {str(files[j])}',fontsize =12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "     ##export out files to make the next few plots w/o normalization\n",
    "    pickle.dump(eur_posXtest, open(f'./index/pos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FposXtest, open(f'./index/Fpos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_negXtest, open(f'./index/neg_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FnegXtest, open(f'./index/Fneg_{str(files[j])}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83848e0e-0236-4c5c-89c3-864a078a9835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 AI Environment",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
