{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191cb9b8",
   "metadata": {},
   "source": [
    "### Random Forests at 14-days leadtime for all regions.\n",
    "\n",
    "File generated 9/18/2025 for Chapter 4 of Dissertation. \n",
    "Modified 12/2/2025 for use in UFS analysis. \n",
    "\n",
    "This file utilizes definition statements containing RF architecture to create three separate RF models, each for a designated forecast region. \n",
    "\n",
    "Forecast leadtime can be changed as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85424968",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 18:50:47.657837: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 18:50:47.700768: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-04 18:50:47.700796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-04 18:50:47.701826: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-04 18:50:47.708442: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 18:50:49.748644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "##just to stop the excess number of warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#relevant import statements\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import sample\n",
    "\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import keras\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698f62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import definitions \n",
    "from SkillStats_MOD import BSS, RAS, PAS\n",
    "\n",
    "from RF_archMOD import rf_featselect,rf_90thpercentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb544f9-6ae8-44cc-885d-3197a9731459",
   "metadata": {},
   "source": [
    "I am going to do a modified version of the architecture def here because I have to change the dataset structure. \n",
    "\n",
    "Start with bringing in the old data for training/validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62081138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 149, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load OG input data, it is max/min standardized, NaNs removed\n",
    "#stratospheric polar vortex ellipse diagnostics from Fernandez et al 2025 (in review)\n",
    "infile = open(\"./old_data/nolag_extendedanom_input.p\", 'rb') \n",
    "nolag_input = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "nolag_input.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf69a",
   "metadata": {},
   "source": [
    "The input data stays the same regardless of forecast region. \n",
    "\n",
    "The original array starts on October 19th. The shift send this forward to November 2nd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d20b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 135 #129 for 20, 119 for 30.\n",
    "inp1 = np.empty((52,idx,7)) #cnew input array, 14 day lag. \n",
    "shift = 14\n",
    "\n",
    "##reshaping to change lag in metrics for input\n",
    "inp1[:,:,0] = nolag_input[:52,shift:,0] ##wind\n",
    "inp1[:,:,1] = nolag_input[:52,shift:,1] ##ratio\n",
    "inp1[:,:,2] = nolag_input[:52,shift:,2] ##latitude\n",
    "inp1[:,:,3] = nolag_input[:52,shift:,3] ##longitude\n",
    "inp1[:,:,4] = nolag_input[:52,shift:,4] ##size\n",
    "inp1[:,:,5] = nolag_input[:52,shift:,5] ##ephi\n",
    "inp1[:,:,6] = nolag_input[:52,shift:,6] ##gph\n",
    "\n",
    "inp = inp1.reshape(52*idx,7)\n",
    "\n",
    "#convert to pandas dataframe\n",
    "input1 = pd.DataFrame(inp)\n",
    "#label columns of variables for input data\n",
    "col_names = ['wind','rat','cenlat','cenlon','size','ephi','gph']\n",
    "input1.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce14c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load in desired TESTING dataset... varies based on prototype.\n",
    "infile = open(\"./new_data/input_ERA5.p\", 'rb') \n",
    "testing_input = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "inp = testing_input.reshape(56*18,7)\n",
    "\n",
    "#convert to pandas dataframe\n",
    "input2 = pd.DataFrame(inp)\n",
    "#label columns of variables for input data\n",
    "col_names = ['wind','rat','cenlat','cenlon','size','ephi','gph']\n",
    "input2.columns = col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40125d95",
   "metadata": {},
   "source": [
    "### Begin RF Feature selection test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e0b99c-85bc-400e-8c4e-994cfb0063cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def feat_imp_plot(important,input1,files):\n",
    "    imp = np.nanmean(important, axis = 0)\n",
    "    imp.shape\n",
    "    \n",
    "    #plot features by relative importance\n",
    "    indices = np.argsort(imp)[::-1]  #sort by importance\n",
    "    c = [\"navy\",\"royalblue\",\"slateblue\",\"blueviolet\",\"darkviolet\",\"purple\",\"mediumvioletred\",\"magenta\"]\n",
    "    \n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.title(f'Average Feature Importances Across 100 CVs, {str(files)}',fontsize =18)\n",
    "    plt.barh(range(input1.shape[1]), imp[indices], align=\"center\", color = c)\n",
    "    plt.yticks(range(input1.shape[1]), input1.columns[indices],fontsize =14)\n",
    "    plt.xticks(fontsize =14)\n",
    "    plt.xlabel(\"Relative Importance\",fontsize =16)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(f'./images/FeatureImportance_{str(files)}.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9a03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of cross validations\n",
    "n = 100\n",
    "\n",
    "regions = ['eur','nova','seus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9a202",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "for i in range(len(regions)):\n",
    "    ##EUROPE\n",
    "    if regions[i] == 'eur':\n",
    "        files = ['Europe_ERA5','Europe_Prototype5','Europe_Prototype6','Europe_Prototype7','Europe_Prototype8']\n",
    "        for j in range(len(files)):\n",
    "            print(f'Working on {str(files[j])} ...')\n",
    "            eur_important = rf_featselect(n,shift,idx,input1,input2,regions[i],files[j])\n",
    "            feat_imp_plot(eur_important,input1,files[j])\n",
    "            print('_____________________________________')\n",
    "    ##CANADA\n",
    "    if regions[i] == 'nova':\n",
    "        files = ['Canada_ERA5','Canada_Prototype5','Canada_Prototype6','Canada_Prototype7','Canada_Prototype8']\n",
    "        for j in range(len(files)):\n",
    "            print(f'Working on {str(files[j])} ...')\n",
    "            can_important = rf_featselect(n,shift,idx,input1,input2,regions[i],files[j])\n",
    "            feat_imp_plot(can_important,input1,files[j])\n",
    "            print('_____________________________________')\n",
    "    ##SEUS\n",
    "    if regions[i] == 'seus':\n",
    "        files = ['SEUS_ERA5','SEUS_Prototype5','SEUS_Prototype6','SEUS_Prototype7','SEUS_Prototype8']\n",
    "        for j in range(len(files)):\n",
    "            print(f'Working on {str(files[j])} ...')\n",
    "            seus_important = rf_featselect(n,shift,idx,input1,input2,regions[i],files[j])\n",
    "            feat_imp_plot(seus_important,input1,files[j])\n",
    "            print('_____________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab1417",
   "metadata": {},
   "source": [
    "## Second RF run post feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef75b9f-00a3-4029-b6d4-96f1827d530e",
   "metadata": {},
   "source": [
    "### Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9782b-65ea-4b65-bde1-51805dad8dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Europe_ERA5 ...\n",
      " \n",
      "Creating lists ...\n",
      " \n",
      "Establishing RF hyperparams ...\n",
      " \n",
      "Begin RF CV.\n"
     ]
    }
   ],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "files = ['Europe_ERA5','Europe_Prototype5','Europe_Prototype6','Europe_Prototype7','Europe_Prototype8']\n",
    "eur_input1 = input1[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "eur_input2 = input2[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "\n",
    "for j in range(len(files)):\n",
    "    print(f'Working on {str(files[j])} ...')\n",
    "    \n",
    "    ##CONSTANT ERA5 OUTPUT\n",
    "    infile = open(f'./new_data/2classtemps_Europe_ERA5.p',\"rb\",)\n",
    "    ERA5_temp = pickle.load(infile) \n",
    "    infile.close()\n",
    "\n",
    "    eur_test90, eur_fulltest, eur_shap_obj, eur_posXtest, eur_FposXtest, eur_negXtest, eur_FnegXtest, acc_reg2_test, acc_reg3_test, acc_reg4_test = rf_90thpercentile(n,shift, idx, eur_input1, eur_input2, ERA5_temp, 'eur', files[j])\n",
    "    #____________________________________________________#\n",
    "    #plot SHAP\n",
    "    plt.title(f'SHAP Values for Negative Europe Temp Anomalies, {str(files[j])}',fontsize =14, y = 1.05)\n",
    "    ax = shap.plots.beeswarm(eur_shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/SHAP_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    #____________________________________________________#\n",
    "    #plot ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(eur_test90, bins=bins)\n",
    "    countsfull, edgesfull = np.histogram(eur_fulltest, bins=bins)\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs for 100 CVs, {str(files[j])}',fontsize =15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "    #plot ERA5 relative ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(acc_reg3_test, bins=bins) ##relative to prediction truth\n",
    "    countsfull, edgesfull = np.histogram(acc_reg2_test, bins=bins) ##relative to ERA5 truth\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='Prototype', align='edge', color='darkorange')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='ERA5', align='edge', color = 'gold')\n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs from ERA5 and Prototype Truth, {str(files[j])}',fontsize =15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/Comp_ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "    ##export out files to make the next few plots w/o normalization\n",
    "    pickle.dump(eur_posXtest, open(f'./index/pos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FposXtest, open(f'./index/Fpos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_negXtest, open(f'./index/neg_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FnegXtest, open(f'./index/Fneg_{str(files[j])}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9232b-a154-4cda-9a1f-056863c6074d",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd590d-53ee-40c9-a2ea-100952da1964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "files = ['Canada_ERA5','Canada_Prototype5','Canada_Prototype6','Canada_Prototype7','Canada_Prototype8']\n",
    "eur_input1 = input1[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "eur_input2 = input2[[\"wind\",\"cenlon\",\"cenlat\",\"gph\"]]\n",
    "\n",
    "for j in range(len(files)):\n",
    "    print(f'Working on {str(files[j])} ...')\n",
    "\n",
    "    ##CONSTANT ERA5 OUTPUT\n",
    "    infile = open(f'./new_data/2classtemps_Canada_ERA5.p',\"rb\",)\n",
    "    ERA5_temp = pickle.load(infile) \n",
    "    infile.close()\n",
    "    \n",
    "    eur_test90, eur_fulltest, eur_shap_obj, eur_posXtest, eur_FposXtest, eur_negXtest, eur_FnegXtest, acc_reg2_test, acc_reg3_test, acc_reg4_test = rf_90thpercentile(n,shift, idx, eur_input1, eur_input2, ERA5_temp, 'nova',files[j])\n",
    "    #____________________________________________________#\n",
    "    #plot SHAP\n",
    "    plt.title(f'SHAP Values for Negative Canadian Temp Anomalies, {str(files[j])}',fontsize =14, y = 1.05)\n",
    "    ax = shap.plots.beeswarm(eur_shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/SHAP_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    #____________________________________________________#\n",
    "    #plot ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(eur_test90, bins=bins)\n",
    "    countsfull, edgesfull = np.histogram(eur_fulltest, bins=bins)\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs for 100 CVs, {str(files[j])}',fontsize =15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "    #plot ERA5 relative ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(acc_reg3_test, bins=bins) ##relative to prediction truth\n",
    "    countsfull, edgesfull = np.histogram(acc_reg2_test, bins=bins) ##relative to ERA5 truth\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='Prototype', align='edge', color='darkorange')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='ERA5', align='edge', color = 'gold')\n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs from ERA5 and Prototype Truth, {str(files[j])}',fontsize =15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/Comp_ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "    ##export out files to make the next few plots w/o normalization\n",
    "    pickle.dump(eur_posXtest, open(f'./index/pos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FposXtest, open(f'./index/Fpos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_negXtest, open(f'./index/neg_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FnegXtest, open(f'./index/Fneg_{str(files[j])}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eacbe6d-5fc0-4169-9820-562228794097",
   "metadata": {},
   "source": [
    "### SEUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc079ec-6b5c-4d43-b9f5-4ab2535895db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on SEUS_ERA5 ...\n",
      " \n",
      "Creating lists ...\n",
      " \n",
      "Establishing RF hyperparams ...\n",
      " \n",
      "Begin RF CV.\n",
      " \n",
      "END CV.\n",
      " \n",
      " \n",
      "###################################################\n",
      "Accuracy, Validation: 61.48%\n",
      "Accuracy, Training: 63.31%\n",
      "Accuracy, Testing: 60.65%\n",
      "_____________________________________________________________________\n",
      "Brier Skill Score (Train): 0.0984\n",
      "Brier Skill Score (Test): 0.0435\n",
      "Brier Skill Score (Validation): 0.0645\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Neg Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.7110\n",
      "Recall Accuracy Score (Test): 0.7249\n",
      "Recall AccuracyScore (Validation): 0.6998\n",
      "Precision Accuracy Score (Train): 0.6271\n",
      "Precision Accuracy Score (Test): 0.6308\n",
      "Precision AccuracyScore (Validation): 0.6111\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Pos Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.5503\n",
      "Recall Accuracy Score (Test): 0.4544\n",
      "Recall AccuracyScore (Validation): 0.5236\n",
      "Precision Accuracy Score (Train): 0.6424\n",
      "Precision Accuracy Score (Test): 0.5625\n",
      "Precision AccuracyScore (Validation): 0.6210\n",
      "_____________________________________________________________________\n",
      "Average Num. of 10% Confident and Correct Postive Predictions: 30.44%\n",
      "Average Num. of 10% Confident and Correct Negative Predictions: 36.18%\n",
      "Average Num. of 10% Confident and FALSE Postive Predictions: 19.58%\n",
      "Average Num. of 10% Confident and FALSE Negative Predictions: 13.80%\n",
      "#######################################################################\n",
      "Average Num. of 10% Confident and Correct Predictions: 66.62%\n",
      "Average Num. of 10% Confident and FALSE Predictions: 33.38%\n",
      " \n",
      " \n",
      "Trying SHAP ...\n",
      "Done.\n",
      "_____________________________________\n",
      "_____________________________________\n",
      "Working on SEUS_Prototype5 ...\n",
      " \n",
      "Creating lists ...\n",
      " \n",
      "Establishing RF hyperparams ...\n",
      " \n",
      "Begin RF CV.\n",
      " \n",
      "END CV.\n",
      " \n",
      " \n",
      "###################################################\n",
      "Accuracy, Validation: 61.18%\n",
      "Accuracy, Training: 63.27%\n",
      "Accuracy, Testing: 53.63%\n",
      "_____________________________________________________________________\n",
      "Brier Skill Score (Train): 0.0985\n",
      "Brier Skill Score (Test): 0.0078\n",
      "Brier Skill Score (Validation): 0.0627\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Neg Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.7084\n",
      "Recall Accuracy Score (Test): 0.6969\n",
      "Recall AccuracyScore (Validation): 0.6933\n",
      "Precision Accuracy Score (Train): 0.6276\n",
      "Precision Accuracy Score (Test): 0.5005\n",
      "Precision AccuracyScore (Validation): 0.6079\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Pos Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.5522\n",
      "Recall Accuracy Score (Test): 0.3971\n",
      "Recall AccuracyScore (Validation): 0.5252\n",
      "Precision Accuracy Score (Train): 0.6407\n",
      "Precision Accuracy Score (Test): 0.6020\n",
      "Precision AccuracyScore (Validation): 0.6183\n",
      "_____________________________________________________________________\n",
      "Average Num. of 10% Confident and Correct Postive Predictions: 38.59%\n",
      "Average Num. of 10% Confident and Correct Negative Predictions: 35.63%\n",
      "Average Num. of 10% Confident and FALSE Postive Predictions: 11.42%\n",
      "Average Num. of 10% Confident and FALSE Negative Predictions: 14.36%\n",
      "#######################################################################\n",
      "Average Num. of 10% Confident and Correct Predictions: 74.22%\n",
      "Average Num. of 10% Confident and FALSE Predictions: 25.78%\n",
      " \n",
      " \n",
      "Trying SHAP ...\n",
      "Done.\n",
      "_____________________________________\n",
      "_____________________________________\n",
      "Working on SEUS_Prototype6 ...\n",
      " \n",
      "Creating lists ...\n",
      " \n",
      "Establishing RF hyperparams ...\n",
      " \n",
      "Begin RF CV.\n",
      " \n",
      "END CV.\n",
      " \n",
      " \n",
      "###################################################\n",
      "Accuracy, Validation: 61.82%\n",
      "Accuracy, Training: 63.22%\n",
      "Accuracy, Testing: 62.17%\n",
      "_____________________________________________________________________\n",
      "Brier Skill Score (Train): 0.0975\n",
      "Brier Skill Score (Test): 0.0624\n",
      "Brier Skill Score (Validation): 0.0680\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Neg Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.7168\n",
      "Recall Accuracy Score (Test): 0.7715\n",
      "Recall AccuracyScore (Validation): 0.7097\n",
      "Precision Accuracy Score (Train): 0.6249\n",
      "Precision Accuracy Score (Test): 0.5910\n",
      "Precision AccuracyScore (Validation): 0.6120\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Pos Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.5422\n",
      "Recall Accuracy Score (Test): 0.4742\n",
      "Recall AccuracyScore (Validation): 0.5206\n",
      "Precision Accuracy Score (Train): 0.6434\n",
      "Precision Accuracy Score (Test): 0.6784\n",
      "Precision AccuracyScore (Validation): 0.6287\n",
      "_____________________________________________________________________\n",
      "Average Num. of 10% Confident and Correct Postive Predictions: 35.12%\n",
      "Average Num. of 10% Confident and Correct Negative Predictions: 30.60%\n",
      "Average Num. of 10% Confident and FALSE Postive Predictions: 14.90%\n",
      "Average Num. of 10% Confident and FALSE Negative Predictions: 19.38%\n",
      "#######################################################################\n",
      "Average Num. of 10% Confident and Correct Predictions: 65.72%\n",
      "Average Num. of 10% Confident and FALSE Predictions: 34.28%\n",
      " \n",
      " \n",
      "Trying SHAP ...\n",
      "Done.\n",
      "_____________________________________\n",
      "_____________________________________\n",
      "Working on SEUS_Prototype7 ...\n",
      " \n",
      "Creating lists ...\n",
      " \n",
      "Establishing RF hyperparams ...\n",
      " \n",
      "Begin RF CV.\n",
      " \n",
      "END CV.\n",
      " \n",
      " \n",
      "###################################################\n",
      "Accuracy, Validation: 61.60%\n",
      "Accuracy, Training: 63.19%\n",
      "Accuracy, Testing: 58.70%\n",
      "_____________________________________________________________________\n",
      "Brier Skill Score (Train): 0.0979\n",
      "Brier Skill Score (Test): 0.0179\n",
      "Brier Skill Score (Validation): 0.0666\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Neg Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.7115\n",
      "Recall Accuracy Score (Test): 0.7496\n",
      "Recall AccuracyScore (Validation): 0.7018\n",
      "Precision Accuracy Score (Train): 0.6256\n",
      "Precision Accuracy Score (Test): 0.5413\n",
      "Precision AccuracyScore (Validation): 0.6126\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Pos Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.5475\n",
      "Recall Accuracy Score (Test): 0.4449\n",
      "Recall AccuracyScore (Validation): 0.5238\n",
      "Precision Accuracy Score (Train): 0.6418\n",
      "Precision Accuracy Score (Test): 0.6706\n",
      "Precision AccuracyScore (Validation): 0.6222\n",
      "_____________________________________________________________________\n",
      "Average Num. of 10% Confident and Correct Postive Predictions: 31.87%\n",
      "Average Num. of 10% Confident and Correct Negative Predictions: 31.34%\n",
      "Average Num. of 10% Confident and FALSE Postive Predictions: 18.14%\n",
      "Average Num. of 10% Confident and FALSE Negative Predictions: 18.65%\n",
      "#######################################################################\n",
      "Average Num. of 10% Confident and Correct Predictions: 63.21%\n",
      "Average Num. of 10% Confident and FALSE Predictions: 36.79%\n",
      " \n",
      " \n",
      "Trying SHAP ...\n",
      "Done.\n",
      "_____________________________________\n",
      "_____________________________________\n",
      "Working on SEUS_Prototype8 ...\n",
      " \n",
      "Creating lists ...\n",
      " \n",
      "Establishing RF hyperparams ...\n",
      " \n",
      "Begin RF CV.\n",
      " \n",
      "END CV.\n",
      " \n",
      " \n",
      "###################################################\n",
      "Accuracy, Validation: 61.05%\n",
      "Accuracy, Training: 63.33%\n",
      "Accuracy, Testing: 59.86%\n",
      "_____________________________________________________________________\n",
      "Brier Skill Score (Train): 0.0991\n",
      "Brier Skill Score (Test): 0.0268\n",
      "Brier Skill Score (Validation): 0.0607\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Neg Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.7158\n",
      "Recall Accuracy Score (Test): 0.7528\n",
      "Recall AccuracyScore (Validation): 0.7029\n",
      "Precision Accuracy Score (Train): 0.6263\n",
      "Precision Accuracy Score (Test): 0.5626\n",
      "Precision AccuracyScore (Validation): 0.6059\n",
      "_____________________________________________________________________\n",
      "Recall and Precision: Pos Cat\n",
      "#########\n",
      "Recall Accuracy Score (Train): 0.5457\n",
      "Recall Accuracy Score (Test): 0.4551\n",
      "Recall AccuracyScore (Validation): 0.5115\n",
      "Precision Accuracy Score (Train): 0.6443\n",
      "Precision Accuracy Score (Test): 0.6645\n",
      "Precision AccuracyScore (Validation): 0.6179\n",
      "_____________________________________________________________________\n",
      "Average Num. of 10% Confident and Correct Postive Predictions: 31.45%\n",
      "Average Num. of 10% Confident and Correct Negative Predictions: 29.91%\n",
      "Average Num. of 10% Confident and FALSE Postive Predictions: 18.57%\n",
      "Average Num. of 10% Confident and FALSE Negative Predictions: 20.07%\n",
      "#######################################################################\n",
      "Average Num. of 10% Confident and Correct Predictions: 61.36%\n",
      "Average Num. of 10% Confident and FALSE Predictions: 38.64%\n",
      " \n",
      " \n",
      "Trying SHAP ...\n",
      "Done.\n",
      "_____________________________________\n",
      "_____________________________________\n"
     ]
    }
   ],
   "source": [
    "##Loop through regions and files to do feature selection.\n",
    "files = ['SEUS_ERA5','SEUS_Prototype5','SEUS_Prototype6','SEUS_Prototype7','SEUS_Prototype8']\n",
    "eur_input1 = input1[[\"wind\",\"size\",\"cenlat\",\"gph\"]]\n",
    "eur_input2 = input2[[\"wind\",\"size\",\"cenlat\",\"gph\"]]\n",
    "\n",
    "for j in range(len(files)):\n",
    "    print(f'Working on {str(files[j])} ...')\n",
    "\n",
    "    ##CONSTANT ERA5 OUTPUT\n",
    "    infile = open(f'./new_data/2classtemps_SEUS_ERA5.p',\"rb\",)\n",
    "    ERA5_temp = pickle.load(infile) \n",
    "    infile.close()\n",
    "    \n",
    "    eur_test90, eur_fulltest, eur_shap_obj, eur_posXtest, eur_FposXtest, eur_negXtest, eur_FnegXtest, acc_reg2_test, acc_reg3_test, acc_reg4_test = rf_90thpercentile(n,shift, idx, eur_input1, eur_input2, ERA5_temp, 'seus', files[j])\n",
    "    #____________________________________________________#\n",
    "    #plot SHAP\n",
    "    plt.title(f'SHAP Values for SEUS Canadian Temp Anomalies, {str(files[j])}',fontsize =14, y = 1.05)\n",
    "    ax = shap.plots.beeswarm(eur_shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/SHAP_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    #____________________________________________________#\n",
    "    #plot ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(eur_test90, bins=bins)\n",
    "    countsfull, edgesfull = np.histogram(eur_fulltest, bins=bins)\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs for 100 CVs, {str(files[j])}',fontsize =15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "    #plot ERA5 relative ACC\n",
    "    bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "    ##bin the testing 90th percentile accuracy data\n",
    "    counts90, edges90 = np.histogram(acc_reg3_test, bins=bins) ##relative to prediction truth\n",
    "    countsfull, edgesfull = np.histogram(acc_reg2_test, bins=bins) ##relative to ERA5 truth\n",
    "    #plot the full dataset\n",
    "    #offset = 0.02  # Adjust this value if needed for better visibility\n",
    "    plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "            edgecolor='black', alpha=0.5, label='Prototype', align='edge', color='darkorange')\n",
    "    \n",
    "    #plot the 90th percentile\n",
    "    plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "            edgecolor='black', alpha=0.5, label='ERA5', align='edge', color = 'gold')\n",
    "    plt.xlabel('Accuracy',fontsize =14)\n",
    "    plt.ylabel('Number of Models',fontsize =14)\n",
    "    plt.legend()\n",
    "    plt.title(f'Testing ACCs from ERA5 and Prototype Truth, {str(files[j])}',fontsize =15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./images/Comp_ACC_{str(files[j])}.png')\n",
    "    plt.close()\n",
    "    print('_____________________________________')\n",
    "    #____________________________________________________#\n",
    "     ##export out files to make the next few plots w/o normalization\n",
    "    pickle.dump(eur_posXtest, open(f'./index/pos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FposXtest, open(f'./index/Fpos_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_negXtest, open(f'./index/neg_{str(files[j])}.p', 'wb'))\n",
    "    pickle.dump(eur_FnegXtest, open(f'./index/Fneg_{str(files[j])}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83848e0e-0236-4c5c-89c3-864a078a9835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 AI Environment",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
