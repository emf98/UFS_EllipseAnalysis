{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab55179f-0697-4a37-b046-2ed5cb452b9e",
   "metadata": {},
   "source": [
    "## Obtain UFS data by area. \n",
    "\n",
    "GPH and Temp?\n",
    "\n",
    "Created 12/4/2025. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09cd945-a179-4276-84b0-a23b646a6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports for relevant packages \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0333a4-e96e-4883-a6ec-e7c78a29b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified to work with this data. \n",
    "def daily_anomaly(target):\n",
    "    #daily mean across years AND forecasts\n",
    "    dailymean = np.nanmean(target, axis=(0, 1))\n",
    "    anom = target - dailymean[None, None, :]\n",
    "    return anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c072a5-a06f-4731-8eac-58ba9e28e259",
   "metadata": {},
   "source": [
    "Start with are weighted GPH at 100hPa over the North Atlantic.\n",
    "\n",
    "lat=slice(80,30),lon = slice(260,350)\n",
    "\n",
    "I need all year/forecast combos available to calculate the anomaly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f8407d-f379-4ca5-8dc6-760b5209143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists to loop through for naming strings per season. \n",
    "years = [y for y in range(2011,2018,1)]\n",
    "month_date = [(11,1),(11,15),(12,1),(12,15),(1,1),(1,15),(2,1),(2,15)]\n",
    "#indicate list of potential prototypes\n",
    "prototype = [\"Prototype5\",\"Prototype6\",\"Prototype7\",\"Prototype8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b296fc-eee0-45e5-b9c0-c3b281ace94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototype5 running ...\n",
      "Finish collecting by Prototype...\n",
      "Prototype6 running ...\n",
      "Finish collecting by Prototype...\n",
      "Prototype7 running ...\n",
      "Finish collecting by Prototype...\n",
      "Prototype8 running ...\n",
      "Finish collecting by Prototype...\n"
     ]
    }
   ],
   "source": [
    "geopotential = np.empty((7,8,4,36, 201,1440))\n",
    "#conduct loop to calculate and save GPH metric.\n",
    "for p in range(len(prototype)):\n",
    "    dummy = np.empty((7,8,36,201,1440))\n",
    "    print(f'{prototype[p]} running ...')\n",
    "    for i in range(len(years)):\n",
    "        for j in range(len(month_date)):\n",
    "            if month_date[j][0] == 11 or month_date[j][0] == 12:\n",
    "                #designate file-specific date\n",
    "                date_str = f\"{years[i]}{month_date[j][0]:02d}{month_date[j][1]:02d}\"\n",
    "                #open file\n",
    "                gfile = xr.open_dataset( f\"/network/rit/lab/wulab/forecast/s2s/ufs/{prototype[p]}/gh/gh_plevs_{date_str}.nc\")\n",
    "                g_files = gfile[\"gh\"]\n",
    "                #g_data = g_files.loc[dict(latitude=slice(80,30),longitude=slice(260,350),lev=100)]\n",
    "                g_data = g_files.loc[dict(latitude=slice(90,40),lev=100)]\n",
    "                #append to dummy array\n",
    "                dummy[i,j,:] = g_data\n",
    "\n",
    "            else:\n",
    "                #designate file-specific date\n",
    "                date_str = f\"{years[i]+1}{month_date[j][0]:02d}{month_date[j][1]:02d}\"\n",
    "                #open file\n",
    "                gfile = xr.open_dataset( f\"/network/rit/lab/wulab/forecast/s2s/ufs/{prototype[p]}/gh/gh_plevs_{date_str}.nc\")\n",
    "                g_files = gfile[\"gh\"]\n",
    "                #g_data = g_files.loc[dict(latitude=slice(80,30),longitude=slice(260,350),lev=100)]\n",
    "                g_data = g_files.loc[dict(latitude=slice(90,40),lev=100)]\n",
    "                #append to dummy array\n",
    "                dummy[i,j,:] = g_data\n",
    "    print(\"Finish collecting by Prototype...\")\n",
    "    #calculate day/year anomaly\n",
    "    geopotential[:,:,p,:] = daily_anomaly(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8463fc09-84ca-4981-8243-d0cf76e12af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send out GPH anomalies\n",
    "pickle.dump(geopotential, open(\"./UFS_metrics/CAP_UFS_GPHanoms100.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5042e92-9dfb-4502-8f45-9dca4a1ab6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"./era5/1959composite_capGPH100.p\", 'rb') \n",
    "gph = pickle.load(infile)\n",
    "gph = gph[:62,31:].reshape((62,152,26,180))\n",
    "#remove leap year\n",
    "gph = np.delete(gph,[120],1)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f37c1f-412c-438e-82a2-6b21375b5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty arrays for ERA5 \n",
    "g = np.empty((7,8,36,26,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f70b7f-d66b-4809-88c7-f1629c46d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [y for y in range(52,59,1)]\n",
    "index = [0,14,30,44,61,75,92,106]\n",
    "\n",
    "for i in range(len(years)):\n",
    "    year = years[i] #make sure proper index is used for the ERA-5.\n",
    "    #i is preserved to index the copy array properly. \n",
    "    for j in range(len(index)):\n",
    "        ind = index[j]\n",
    "        g[i,j,:,:,:] = daily_anomaly(gph[year,ind:ind+36,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efbd1280-eca0-40dc-ba52-9260643dfd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export/dump the arrays into file\n",
    "pickle.dump(g, open(\"./UFS_metrics/CAP_ERA5_GPHanoms100.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f980606-c41f-47e4-97b8-375b0bb44bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 AI Environment",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
